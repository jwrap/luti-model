{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle, warnings, sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from trip_assignment import *\n",
    "from trip_generation import *\n",
    "from trip_distribution import *\n",
    "from mode_split import *\n",
    "from luti_run import *\n",
    "from hh_updating import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:54:59.398235Z",
     "start_time": "2025-03-04T08:54:57.477366Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dat = gpd.read_file(\"inputs/zone_data.gpkg\")\n",
    "zone_codes = dat['ZONE_CODE'].tolist()\n",
    "attraction_predictors = ['JOBS', 'GREEN_DENSITY']\n",
    "production_predictors = ['POPULATION']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:54:59.463495Z",
     "start_time": "2025-03-04T08:54:59.399704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load road and bike networks\n",
    "road_edges = gpd.read_file(\"inputs/roadNt_edges.gpkg\")\n",
    "road_nodes = gpd.read_file(\"inputs/roadNt_nodes.gpkg\")\n",
    "road_edges['lanes'] = road_edges['lanes'].astype(int)\n",
    "\n",
    "bike_edges = gpd.read_file(\"inputs/bikeNt_edges.gpkg\")\n",
    "bike_nodes = gpd.read_file(\"inputs/bikeNt_nodes.gpkg\")\n",
    "bike_edges['lanes'] = bike_edges['lanes'].astype(int)\n",
    "\n",
    "walk_edges = gpd.read_file(\"inputs/bikeNt_edges.gpkg\")\n",
    "walk_nodes = gpd.read_file(\"inputs/bikeNt_nodes.gpkg\")\n",
    "walk_edges['lanes'] = walk_edges['lanes'].astype(int)\n",
    "\n",
    "# Load pre-calculated travel times\n",
    "w_tt = pickle.load(open(\"inputs/walk_tt_matrix.pickle\", \"rb\"))\n",
    "d_tt = pickle.load(open(\"inputs/road_tt_matrix.pickle\", \"rb\"))\n",
    "b_tt = pickle.load(open(\"inputs/bike_tt_matrix.pickle\", \"rb\"))\n",
    "\n",
    "# Ensure the matrices are ordered consistently for matrix operations (if any)\n",
    "w_tt = order_impedance_matrices(w_tt, zone_codes)\n",
    "d_tt = order_impedance_matrices(d_tt, zone_codes)\n",
    "b_tt = order_impedance_matrices(b_tt, zone_codes)\n",
    "travel_times = {\"WALK\":w_tt, \"DRIVE\":d_tt, \"BIKE\":b_tt}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:54:59.874993Z",
     "start_time": "2025-03-04T08:54:59.474614Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "network_mode_split = pd.read_csv(\"inputs/network_mode_split.csv\").set_index('MODE')\n",
    "trip_distr_params = pd.read_csv(\"inputs/trip_distribution_params.csv\").set_index('PARAMETER')\n",
    "n, b = trip_distr_params.loc['n', 'VALUE'], trip_distr_params.loc['b', 'VALUE']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:54:59.882247Z",
     "start_time": "2025-03-04T08:54:59.876746Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing network\n",
      "initialized network\n",
      "Generating contraction hierarchies with 12 threads.\n",
      "Setting CH node vector of size 6109\n",
      "Setting CH edge vector of size 6864\n",
      "Range graph removed 984 edges of 13728\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 12 threads.\n",
      "Setting CH node vector of size 6109\n",
      "Setting CH edge vector of size 6864\n",
      "Range graph removed 984 edges of 13728\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% initialized pandana network\n",
      "calculated shortest path lengths, now updating potential_volume\n",
      "start of iteration: 1\n",
      "Generating contraction hierarchies with 12 threads.\n",
      "Setting CH node vector of size 6109\n",
      "Setting CH edge vector of size 6864\n",
      "Range graph removed 58 edges of 13728\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 12 threads.\n",
      "Setting CH node vector of size 6109\n",
      "Setting CH edge vector of size 6864\n",
      "Range graph removed 984 edges of 13728\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% end of iteration: 1 \t\t cal_limit: 107.7236328125 \t\t step: 0.00048828125\n",
      "Generating contraction hierarchies with 12 threads.\n",
      "Setting CH node vector of size 15832\n",
      "Setting CH edge vector of size 23254\n",
      "Range graph removed 12882 edges of 46508\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      "Generating contraction hierarchies with 12 threads.\n",
      "Setting CH node vector of size 15832\n",
      "Setting CH edge vector of size 23254\n",
      "Range graph removed 12882 edges of 46508\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      "Generating contraction hierarchies with 12 threads.\n",
      "Setting CH node vector of size 15832\n",
      "Setting CH edge vector of size 23254\n",
      "Range graph removed 12882 edges of 46508\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      "Generating contraction hierarchies with 12 threads.\n",
      "Setting CH node vector of size 15832\n",
      "Setting CH edge vector of size 23254\n",
      "Range graph removed 12882 edges of 46508\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    }
   ],
   "source": [
    "# (1) Estimate Production and Attraction using a Poisson regression model for the first (0) time step\n",
    "production, attraction = trip_generation(dat, attraction_predictors,\n",
    "                                         production_predictors,\n",
    "                                         zone_codes, time_step=0)\n",
    "\n",
    "# (2) Distributes trips from Origins to Destinations based on assumesd trip distribution parameters.\n",
    "T_ij = trip_distribution(car_ownership=dat['BASELINE_CAR_OWNERSHIP'],\n",
    "                         P=production,\n",
    "                         A=attraction,\n",
    "                         travel_times = travel_times,\n",
    "                         network_mode_split= network_mode_split,\n",
    "                         n=n, b=b,\n",
    "                         zone_codes=zone_codes)\n",
    "\n",
    "# (3) Splits the distributed trips across the considered modes\n",
    "od_matrices = mode_split_aggregated(travel_times, T_ij)\n",
    "\n",
    "# (4) Assign all mode-specific trips across the relevant network\n",
    "# Use of the trip_assignment_capped function assumes that the Road network have capacity constraints\n",
    "road_edges_df, road_nodes_df, roadNt_nodeID_mapping = prepare_capped_network(road_edges, road_nodes,\n",
    "                                                                             base_capacity=1000)\n",
    "road_capacity_df, road_tt, road_dist = trip_assignment_capped(road_edges_df, road_nodes_df,\n",
    "                                                              roadNt_nodeID_mapping, zone_codes,\n",
    "                                                              od_matrices['DRIVE'],\n",
    "                                                              convergence_criteria=0.2)\n",
    "\n",
    "# Use of the trip_assignment_uncapped function assumes that the Bike/Walk network capacity constraint need not be considered\n",
    "cycle_edge_df, cycle_node_df, bikeNt_nodeID_mapping = prepare_uncapped_network(bike_edges, bike_nodes,\n",
    "                                                                               base_capacity=99999)\n",
    "bike_capacity_df, bike_tt, bike_dist = trip_assignment_uncapped(cycle_edge_df, cycle_node_df,\n",
    "                                                                bikeNt_nodeID_mapping, b_tt,\n",
    "                                                                zone_codes, od_matrices['BIKE'])\n",
    "\n",
    "walk_edge_df, walk_node_df, walkNt_nodeID_mapping = prepare_uncapped_network(walk_edges, walk_nodes,\n",
    "                                                                             base_capacity=99999)\n",
    "walk_capacity_df, walk_tt, walk_dist = trip_assignment_uncapped(walk_edge_df, walk_node_df,\n",
    "                                                                walkNt_nodeID_mapping, w_tt,\n",
    "                                                                zone_codes, od_matrices['WALK'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:55:06.222051Z",
     "start_time": "2025-03-04T08:54:59.892397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# (5) Uses trip assignment outputs to inform impedance function of LUTI calculations\n",
    "# Sets intrazonal travel time to fixed values of 5/10/15 minutes for drive/bike/walk respectively\n",
    "# Caps maximum travel time at 90 minutes and minimum travel time at 1 minute\n",
    "cijs = {}\n",
    "cijs['DRIVE'] = load_cij(od_matrix=road_tt.pivot(index='Origin', columns='Destination', values='TT'),\n",
    "                         intrazonal_tt=pd.DataFrame({\"ZONE_CODE\": zone_codes,\n",
    "                                                     \"TT\": [5 for x in zone_codes]}),\n",
    "                         zone_codes=zone_codes,\n",
    "                         upper_threshold=90.0,\n",
    "                         lower_threshold=1.0)\n",
    "cijs['BIKE'] = load_cij(od_matrix=bike_tt.pivot(index='Origin', columns='Destination', values='TT'),\n",
    "                        intrazonal_tt=pd.DataFrame({\"ZONE_CODE\": zone_codes,\n",
    "                                                    \"TT\": [10 for x in zone_codes]}),\n",
    "                        zone_codes=zone_codes,\n",
    "                        upper_threshold=90.0,\n",
    "                        lower_threshold=1.0)\n",
    "cijs['WALK'] = load_cij(od_matrix=walk_tt.pivot(index='Origin', columns='Destination', values='TT'),\n",
    "                        intrazonal_tt= pd.DataFrame({\"ZONE_CODE\": zone_codes,\n",
    "                                                     \"TT\": [15 for x in zone_codes]}),\n",
    "                        zone_codes=zone_codes,\n",
    "                        upper_threshold= 90.0,\n",
    "                        lower_threshold= 1.0)\n",
    "\n",
    "Sij, Beta, CBarPred = runCalculationsSimple(ODs=od_matrices, cijs=cijs,\n",
    "                                            df_Employment=dat[['ZONE_CODE', 'BASELINE_JOBS']],\n",
    "                                            df_Residential= dat[['ZONE_CODE', 'BASELINE_POPULATION']],\n",
    "                                            attractor='BASELINE_POPULATION',\n",
    "                                            control='BASELINE_JOBS',\n",
    "                                            convergence_criteria=0.2)\n",
    "\n",
    "luti = luti_outputSimple(Sij=Sij,\n",
    "                         data_input=dat,\n",
    "                         production_var='BASELINE_POPULATION',\n",
    "                         attraction_var='BASELINE_JOBS')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:56:27.844244Z",
     "start_time": "2025-03-04T08:56:27.778625Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
